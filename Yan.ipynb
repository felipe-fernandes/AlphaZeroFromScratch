{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import diff\n",
    "from numpy import sum\n",
    "from random import randint\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from models_params import Models_Params\n",
    "import jsonpickle\n",
    "\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yan:\n",
    "    def __init__(self):\n",
    "        # iniciar a coluna da desordem com -1 para indicar que as celulas estão vazias\n",
    "        self.desordem = {\"1\": -1, \"2\": -1, \"3\": -1, \"4\": -1, \"5\": -1, \"6\": -1, \"q\": -1, \"f\": -1, \"s+\": -1, \"s-\": -1, \"x+\": -1, \"x-\": -1, \"y\": -1}\n",
    "        self.yangame = \"YanGame\"\n",
    "        self.rolls_left = 2\n",
    "        self.dices = [0,0,0,0,0]\n",
    "        self.new_dice = list()\n",
    "        self.marcado_em = \"\"\n",
    "        self.over_minimum = False\n",
    "        self.is_ended = False\n",
    "        self.game_play = []\n",
    "        self.next_state = self.get_game_state()\n",
    "        self.reward = 0\n",
    "        self.valid_moves_items = []\n",
    "        \n",
    "\n",
    "    def check_consecutive(self, l):\n",
    "        n = len(l) - 1\n",
    "        return sum(diff(sorted(l)) == 1) >= n\n",
    "\n",
    "\n",
    "    def roll_dice(self, n):\n",
    "        # random.seed(42)\n",
    "\n",
    "        rolls = list()\n",
    "        for i in range(n):\n",
    "            rolls.append(randint(1, 6))\n",
    "        rolls.sort()\n",
    "        self.game_play.append(\"você rolou:                          \" + str(rolls))\n",
    "        return rolls\n",
    "\n",
    "\n",
    "    def get_game_state(self):\n",
    "        state = [self.rolls_left]\n",
    "        for die in self.dices:\n",
    "            state.append(die)\n",
    "        for item in self.desordem:\n",
    "            if self.desordem[item] == -1:\n",
    "                state.append(1)\n",
    "            else:\n",
    "                state.append(0)\n",
    "        return state\n",
    "        \n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.is_ended = False\n",
    "        # state = ast.literal_eval(state)\n",
    "        self.rolls_left = state[0]\n",
    "        index = 1\n",
    "        for die in range(len(self.dices)):\n",
    "            self.dices[die] = state[index]\n",
    "            index += 1\n",
    "\n",
    "        index = 6\n",
    "        for item in self.desordem:\n",
    "            if state[index] == 1:\n",
    "                self.desordem[item] = -1\n",
    "            else:\n",
    "                self.desordem[item] = 0\n",
    "            index += 1\n",
    "\n",
    "        return self.get_game_state()\n",
    "\n",
    "\n",
    "    def get_empty_cells(self, state):\n",
    "        self.set_state(state)\n",
    "        avaiable_list = {}\n",
    "        for item in self.desordem:\n",
    "            if self.desordem[item] == -1:\n",
    "                avaiable_list[item] = self.desordem[item]\n",
    "        return avaiable_list\n",
    "    \n",
    "\n",
    "    def get_number_of_actions(self, state):\n",
    "        return 13\n",
    "\n",
    "\n",
    "    def do_the_reroll(self, n_dices):\n",
    "        dices_to_reroll = '{0:05b}'.format(int(n_dices))\n",
    "        self.game_play.append(\"dados a serem rolados novamente:     \" + dices_to_reroll)\n",
    "        for index in range(len(str(dices_to_reroll))):\n",
    "            if dices_to_reroll[index] == \"1\":\n",
    "                self.dices[index] = self.roll_dice(1)[0]\n",
    "\n",
    "        self.dices.sort()\n",
    "        self.game_play.append(\"seus dados ficaram assim:            \" + str(self.dices))\n",
    "        # dice_set = set(self.dices)\n",
    "        # n_single = len(dice_set)\n",
    "        # return (6 - n_single) * 3\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.game_play = []\n",
    "        self.game_play.append(\"Jogo iniciado\")\n",
    "        self.desordem = {\"1\": -1, \"2\": -1, \"3\": -1, \"4\": -1, \"5\": -1, \"6\": -1, \"q\": -1, \"f\": -1, \"s+\": -1, \"s-\": -1,\n",
    "                         \"x+\": -1, \"x-\": -1,\n",
    "                         \"y\": -1}\n",
    "        self.dices = self.roll_dice(5)\n",
    "        self.dices.sort()\n",
    "        self.is_ended = False\n",
    "        self.rolls_left = 2\n",
    "        self.valid_moves_items = []\n",
    "        # random.seed(42)\n",
    "\n",
    "        initial_table = randint(1,8191)\n",
    "        tabela = \"{0:b}\".format(initial_table)\n",
    "        n_off_zeros = 13 - len(tabela)\n",
    "        for i in range(n_off_zeros):\n",
    "            tabela = \"0\" + tabela\n",
    "\n",
    "        i = 0\n",
    "        for item in self.desordem:\n",
    "            if tabela[i] == \"1\":\n",
    "                self.desordem[item] = -1\n",
    "            else:\n",
    "                self.desordem[item] = 0\n",
    "            i += 1\n",
    "\n",
    "        self.rolls_left = randint(0,2)\n",
    "\n",
    "        return self.get_game_state()\n",
    "    \n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return self.reset()\n",
    "    \n",
    "\n",
    "    def get_valid_moves(self, state):\n",
    "        self.valid_moves_items = []\n",
    "        valid_action = []\n",
    "        index = 0\n",
    "        for item in self.desordem:\n",
    "            if self.desordem[item] == -1:\n",
    "                self.valid_moves_items.append(item)\n",
    "                valid_action.append(1)\n",
    "            else:\n",
    "                valid_action.append(0)\n",
    "            index += 1\n",
    "        return valid_action\n",
    "\n",
    "\n",
    "    def is_full(self):\n",
    "        return ((self.dices[0] == self.dices[2] and self.dices[3] == self.dices[4]) or (\n",
    "                        self.dices[0] == self.dices[1] and self.dices[2] == self.dices[4]))\n",
    "\n",
    "\n",
    "    def set_cell_value(self, cell: str):\n",
    "\n",
    "        self.is_ended = True\n",
    "        self.game_play.append(\"você marcou                          \" + str(self.dices) + \" em \" + cell)\n",
    "        self.game_play.append(\"\\n\")\n",
    "        \n",
    "        # self.marcado_em = \n",
    "        # print(self.marcado_em)\n",
    "        points = 0\n",
    "\n",
    "        if cell == \"1\":\n",
    "            points = self.dices.count(1)\n",
    "            self.desordem[\"1\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"2\":\n",
    "            points = self.dices.count(2) *2\n",
    "            self.desordem[\"2\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"3\":\n",
    "            points = self.dices.count(3) * 3\n",
    "            self.desordem[\"3\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"4\":\n",
    "            points = self.dices.count(4) * 4\n",
    "            self.desordem[\"4\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"5\":\n",
    "            points = self.dices.count(5) * 5\n",
    "            self.desordem[\"5\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"6\":\n",
    "            points = self.dices.count(6) * 6\n",
    "            self.desordem[\"6\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"y\":\n",
    "            if self.dices[0] == self.dices[4]:\n",
    "                self.desordem[\"y\"] = sum(self.dices) + 50\n",
    "                return sum(self.dices) + 50\n",
    "            else:\n",
    "                self.desordem[\"y\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"q\":\n",
    "            if self.dices[0] == self.dices[3]:\n",
    "                self.desordem[\"q\"] = sum(self.dices[:4]) + 30\n",
    "                return sum(self.dices[:4]) + 30\n",
    "            elif self.dices[1] == self.dices[4]:\n",
    "                self.desordem[\"q\"] = sum(self.dices[1:]) + 30\n",
    "                return sum(self.dices[1:]) + 30\n",
    "            else:\n",
    "                self.desordem[\"q\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"f\":\n",
    "            if self.is_full():\n",
    "                self.desordem[\"f\"] = sum(self.dices) + 20\n",
    "                return sum(self.dices) + 20\n",
    "\n",
    "            else:\n",
    "                self.desordem[\"f\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"s+\":\n",
    "            if self.check_consecutive(self.dices) and self.dices[0] == 2:\n",
    "                self.desordem[\"s+\"] = 60\n",
    "                return 60\n",
    "            else:\n",
    "                self.desordem[\"s+\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"s-\":\n",
    "            if self.check_consecutive( self.dices) and self.dices[0] == 1:\n",
    "                self.desordem[\"s-\"] = 50\n",
    "                return 50\n",
    "            else:\n",
    "                self.desordem[\"s-\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"x+\":\n",
    "            if (sum(self.dices) > self.desordem[\"x-\"]) or self.desordem[\"x-\"] == -1:\n",
    "                self.desordem[\"x+\"] = sum(self.dices)\n",
    "                return sum(self.dices)\n",
    "            else:\n",
    "                self.desordem[\"x+\"] = 0\n",
    "            return 0\n",
    "        \n",
    "        elif cell == \"x-\":\n",
    "            if (sum(self.dices) < self.desordem[\"x+\"]) or self.desordem[\"x+\"] == -1:\n",
    "                self.desordem[\"x-\"] = sum(self.dices)\n",
    "                return sum(self.dices)\n",
    "            else:\n",
    "                self.desordem[\"x-\"] = 0\n",
    "            return 0\n",
    "            \n",
    "\n",
    "    def go_for_n(self, n):\n",
    "        n_count = self.dices.count(n)\n",
    "        if n_count == 5 or self.rolls_left == 0:\n",
    "            self.rolls_left = 2\n",
    "            reward = self.set_cell_value(str(n))\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "            if n_count > 2:\n",
    "                reward *= 2\n",
    "            return reward\n",
    "        else:\n",
    "            for index in range(5):\n",
    "                if self.dices[index] != n:\n",
    "                    self.dices[index] = self.roll_dice(1)[0]\n",
    "\n",
    "        self.rolls_left -= 1\n",
    "        self.dices.sort()\n",
    "        improve = self.dices.count(n) - n_count\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def go_for_y(self):\n",
    "        dices_count = []\n",
    "        for n in range (1,7):\n",
    "            dices_count.append(self.dices.count(n))\n",
    "        if np.max(dices_count) > 4 or self.rolls_left == 0:\n",
    "            self.rolls_left = 2\n",
    "            reward = self.set_cell_value(\"y\")\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "            return reward\n",
    "\n",
    "        if dices_count.count(np.max(dices_count)) > 1:\n",
    "            most_dices_indexs = []\n",
    "            most_dices = None\n",
    "            for index in range(len(dices_count)):\n",
    "                if dices_count[index] == np.max(dices_count):\n",
    "                    most_dices_indexs.append(index + 1)\n",
    "            \n",
    "            #checar qual dado manter dependendo da tabela\n",
    "            for die in most_dices_indexs:\n",
    "                if self.desordem[str(die)] == -1:\n",
    "                    most_dices = die\n",
    "\n",
    "            if most_dices == None:\n",
    "                most_dices = most_dices_indexs[len(most_dices_indexs)-1]\n",
    "        else:        \n",
    "            most_dices = np.argmax(dices_count) + 1\n",
    "\n",
    "        original_most_count_die = self.dices.count(most_dices)\n",
    "\n",
    "        for index in range(5):\n",
    "            if self.dices[index] != most_dices:\n",
    "                self.dices[index] = self.roll_dice(1)[0]\n",
    "\n",
    "        self.dices.sort()\n",
    "        self.rolls_left -= 1\n",
    "        final_most_count_die = self.dices.count(most_dices)\n",
    "        improve = final_most_count_die - original_most_count_die\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def go_for_q(self):\n",
    "        dices_count = []\n",
    "        for n in range (1,7):\n",
    "            dices_count.append(self.dices.count(n))\n",
    "        if np.max(dices_count) > 3 or self.rolls_left == 0:\n",
    "            self.rolls_left = 2\n",
    "            reward = self.set_cell_value(\"q\")\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "            return reward\n",
    "\n",
    "        if dices_count.count(np.max(dices_count)) > 1:\n",
    "            most_dices_indexs = []\n",
    "            most_dices = None\n",
    "            for index in range(len(dices_count)):\n",
    "                if dices_count[index] == np.max(dices_count):\n",
    "                    most_dices_indexs.append(index + 1)\n",
    "            \n",
    "            #checar qual dado manter dependendo da tabela\n",
    "            for die in most_dices_indexs:\n",
    "                if self.desordem[str(die)] == -1:\n",
    "                    most_dices = die\n",
    "\n",
    "            if most_dices == None:\n",
    "                most_dices = most_dices_indexs[len(most_dices_indexs)-1]\n",
    "        else:        \n",
    "            most_dices = np.argmax(dices_count) + 1\n",
    "\n",
    "        original_most_count_die = self.dices.count(most_dices)\n",
    "\n",
    "        for index in range(5):\n",
    "            if self.dices[index] != most_dices:\n",
    "                self.dices[index] = self.roll_dice(1)[0]\n",
    "\n",
    "        self.dices.sort()\n",
    "        self.rolls_left -= 1\n",
    "        final_most_count_die = self.dices.count(most_dices)\n",
    "        improve = final_most_count_die - original_most_count_die\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def get_dices_for_f(self):\n",
    "        dices_count = []\n",
    "        least_dices = None\n",
    "        most_dices = None\n",
    "\n",
    "\n",
    "        for n in range (1,7):\n",
    "            dices_count.append(self.dices.count(n))\n",
    "\n",
    "        if dices_count.count(np.max(dices_count)) == 2:\n",
    "            for index in range(len(dices_count)):\n",
    "                if dices_count[index] == 1:\n",
    "                    least_dices = (index + 1)\n",
    "\n",
    "        elif dices_count.count(np.max(dices_count)) == 1:\n",
    "            most_dices = np.argmax(dices_count) +1\n",
    "\n",
    "        elif dices_count.count(np.max(dices_count)) > 2:\n",
    "            most_dices = None\n",
    "            most_dices_indexs = []\n",
    "            for index in range(len(dices_count)):\n",
    "                if dices_count[index] == np.max(dices_count):\n",
    "                    most_dices_indexs.append(index + 1)\n",
    "            \n",
    "            #checar qual dado manter dependendo da tabela\n",
    "            for die in most_dices_indexs:\n",
    "                if self.desordem[str(die)] == -1:\n",
    "                    most_dices = die\n",
    "\n",
    "            if most_dices == None:\n",
    "                most_dices = most_dices_indexs[len(most_dices_indexs)-1]\n",
    "\n",
    "        return least_dices, most_dices\n",
    "\n",
    "\n",
    "    def go_for_f(self):\n",
    "        \n",
    "        if self.is_full() or self.rolls_left == 0:\n",
    "            self.rolls_left = 2\n",
    "            reward = self.set_cell_value(\"f\")\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "            return reward\n",
    "        \n",
    "        initial_least_dices, initial_most_dices = self.get_dices_for_f()\n",
    "\n",
    "        initial_count = 0\n",
    "        final_count = 0\n",
    "\n",
    "        if initial_least_dices != None:\n",
    "            initial_count = 1\n",
    "            for index in range(5):\n",
    "                if self.dices[index] == initial_least_dices:\n",
    "                    self.dices[index] = self.roll_dice(1)[0]\n",
    "            \n",
    "        if initial_most_dices != None:\n",
    "            initial_count = self.dices.count(initial_most_dices)\n",
    "            for index in range(5):\n",
    "                if self.dices[index] != initial_most_dices:\n",
    "                    self.dices[index] = self.roll_dice(1)[0]\n",
    "            \n",
    "        final_least_dices, final_most_dices = self.get_dices_for_f()\n",
    "        if initial_least_dices != None:\n",
    "            if final_least_dices == None:\n",
    "                final_count = 1\n",
    "            else:\n",
    "                final_count = 0\n",
    "        else:\n",
    "            if final_least_dices != None:\n",
    "                final_count = 2 + (2 - initial_count)\n",
    "            else:\n",
    "                final_count = self.dices.count(final_most_dices) - initial_count\n",
    "\n",
    "        self.dices.sort()\n",
    "        self.rolls_left -= 1\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def get_reroll_dices_s(self, witch_s):\n",
    "        dices_count = []\n",
    "        for n in range (1,7):\n",
    "            dices_count.append(self.dices.count(n))\n",
    "            \n",
    "        reroll_dices = []\n",
    "\n",
    "        if witch_s == \"s+\":\n",
    "            for n in range(dices_count[0]):\n",
    "                reroll_dices.append(1)\n",
    "                \n",
    "            for index in range(1, 6):\n",
    "                for quant in range(dices_count[index] - 1):\n",
    "                    reroll_dices.append(index + 1)\n",
    "\n",
    "        else:\n",
    "            for n in range(dices_count[5]):\n",
    "                reroll_dices.append(6)\n",
    "\n",
    "            for index in range(5):\n",
    "                for quant in range(dices_count[index] - 1):\n",
    "                    reroll_dices.append(index + 1)\n",
    "       \n",
    "        reroll_dices.sort()\n",
    "\n",
    "        return reroll_dices\n",
    "\n",
    "\n",
    "    def go_for_s(self, witch_s):\n",
    "        \n",
    "        if self.rolls_left == 0:\n",
    "            self.rolls_left = 2\n",
    "            reward = self.set_cell_value(witch_s)\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "            return reward\n",
    "        \n",
    "        if self.check_consecutive(self.dices) and self.dices[0] == 2 and witch_s == \"s+\":\n",
    "            self.rolls_left = 2\n",
    "            reward = self.set_cell_value(\"s+\")\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "            return reward\n",
    "        \n",
    "        if self.check_consecutive(self.dices) and self.dices[0] == 1 and witch_s == \"s-\":\n",
    "            self.rolls_left = 2\n",
    "            reward = self.set_cell_value(\"s-\")\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "            return reward\n",
    "        \n",
    "        reroll_dices = self.get_reroll_dices_s(witch_s)\n",
    "        original_n_dice_roled = len(reroll_dices)\n",
    "\n",
    "        for index in range(5):\n",
    "            if self.dices[index] in reroll_dices:\n",
    "                reroll_dices = np.delete(reroll_dices, 0)\n",
    "                self.dices[index] = self.roll_dice(1)[0]\n",
    "\n",
    "        self.rolls_left -= 1\n",
    "        self.dices.sort()\n",
    "        final_n_dice_roled = len(self.get_reroll_dices_s(witch_s))\n",
    "        improve = original_n_dice_roled - final_n_dice_roled\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    def get_next_state(self, state, action):\n",
    "        if action == None:\n",
    "            return (self.get_game_state(), 0, self.is_ended)\n",
    "        self.set_state(state)\n",
    "        action = int(action)\n",
    "        self.reward = 0\n",
    "\n",
    "        if action < 6:\n",
    "            self.reward = self.go_for_n(action+1)/20\n",
    "        elif action == 6:\n",
    "            self.reward = self.go_for_q()*10\n",
    "        elif action == 7:\n",
    "            self.reward = self.go_for_f()*10\n",
    "        elif action == 8:\n",
    "            self.reward = self.go_for_s(\"s+\")*10\n",
    "        elif action == 9:\n",
    "            self.reward = self.go_for_s(\"s-\")*10\n",
    "        elif action == 10:\n",
    "            self.rolls_left = 2\n",
    "            self.reward = self.set_cell_value(\"x+\")\n",
    "            self.reward = 0\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "        elif action == 11:\n",
    "            self.rolls_left = 2\n",
    "            self.reward = self.set_cell_value(\"x-\")\n",
    "            self.reward = 0\n",
    "            self.dices = self.roll_dice(5)\n",
    "            self.dices.sort()\n",
    "        elif action == 12:\n",
    "            self.reward = self.go_for_y()*10\n",
    "        else:\n",
    "            breakpoint()\n",
    "            print(action)\n",
    "        return (self.get_game_state(), self.reward, self.is_ended)\n",
    "\n",
    "\n",
    "    # def check_ended(self, state):\n",
    "    #     self.set_state(state)\n",
    "    #     return -1 not in self.desordem.values()\n",
    "    \n",
    "\n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if action == None:\n",
    "            return (0, False)\n",
    "        self.set_state(state)\n",
    "        next_state, reward, is_ended = self.get_next_state(state, action)\n",
    "        return reward, is_ended\n",
    "    \n",
    "\n",
    "    def get_total_score(self, state):\n",
    "        self.set_state(state)\n",
    "        self.score_values = list(self.desordem.values())\n",
    "        self.total = sum(self.score_values)\n",
    "        total_upper = sum(self.score_values[0:6])\n",
    "        if total_upper >= 60:\n",
    "            self.total += 30\n",
    "        # print()\n",
    "        self.game_play.append(\"sua tabela ficou assim:              \" + str(self.desordem))\n",
    "        self.game_play.append(\"TOTAL:                               \" + str(self.total))\n",
    "        # print(\"total: \", self.total)\n",
    "        # print(\"sua tabela ficou assim: \", self.desordem)\n",
    "        # print()\n",
    "        \n",
    "\n",
    "        return self.total\n",
    "    \n",
    "\n",
    "    def get_encoded_state(self, state):\n",
    "\n",
    "        encoded_state = []\n",
    "        encoded_state.append(state[0]/2)\n",
    "        for i in range(1,6):\n",
    "            encoded_state.append(state[i]/6)\n",
    "        encoded_state += state[6:]\n",
    "        return encoded_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 13\n",
    "NUM_FEATURES = 3\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, num_resBlocks, num_hidden):\n",
    "        super().__init__()\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Linear(in_features=19, out_features=num_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
    "        )\n",
    "        \n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Linear(in_features=num_hidden, out_features=num_hidden),\n",
    "            # nn.BatchNorm1d(num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, 13)\n",
    "        )\n",
    "        \n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Linear(in_features=num_hidden, out_features=num_hidden),\n",
    "            # nn.BatchNorm1d(num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "        \n",
    "        \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_features=num_hidden, out_features=num_hidden)\n",
    "        # self.bn1 = nn.BatchNorm1d(num_hidden)\n",
    "        self.lin2 = nn.Linear(in_features=num_hidden, out_features=num_hidden)\n",
    "        # self.bn2 = nn.BatchNorm1d(num_hidden)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game:Yan, args, state, parent=None, action_taken=None, prior=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior\n",
    "        \n",
    "        self.children = []\n",
    "        \n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "        \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "        \n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "                \n",
    "        return best_child\n",
    "    \n",
    "    def get_ucb(self, child):\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = ((child.value_sum / child.visit_count) + 1) / 2\n",
    "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
    "    \n",
    "    def expand(self, policy):\n",
    "        child = None\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob > 0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state, child_reward, child_terminated = self.game.get_next_state(child_state, action)\n",
    "\n",
    "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
    "                self.children.append(child)\n",
    "        if child == None:\n",
    "            breakpoint()\n",
    "        return child\n",
    "    \n",
    "            \n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "        \n",
    "        # value = self.game.reward\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)  \n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game:Yan, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "    @torch.no_grad() \n",
    "    def search(self, state):\n",
    "        root = Node(self.game, self.args, state)\n",
    "        \n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "            \n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "                \n",
    "            state, value, is_terminal = self.game.get_next_state(node.state, node.action_taken)\n",
    "            \n",
    "            if not is_terminal:\n",
    "                tensor = torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)\n",
    "                policy_init, value = self.model(\n",
    "                    tensor.float()\n",
    "                )   \n",
    "                \n",
    "                if np.isnan(policy_init[0][0]):\n",
    "                    breakpoint()\n",
    "                policy = torch.softmax(policy_init, axis=1).squeeze(0).cpu().numpy()\n",
    "                valid_moves = self.game.get_valid_moves(node.state)\n",
    "                policy *= valid_moves\n",
    "                sum_policy = np.sum(policy)\n",
    "                if sum_policy != 0:\n",
    "                    policy = policy/sum_policy\n",
    "                    node.expand(policy)\n",
    "\n",
    "                # if np.isnan(out_policy[0]):\n",
    "                #     out_policy = torch.softmax(policy_init, axis=1).squeeze(0).cpu().numpy()\n",
    "                #     out_policy *= valid_moves\n",
    "                # else:\n",
    "                #     breakpoint()\n",
    "                value = value.item()\n",
    "                \n",
    "\n",
    "            node.backpropagate(value)    \n",
    "            \n",
    "            \n",
    "        # action_probs = self.game.get_valid_moves(state)\n",
    "        action_probs = np.zeros(13)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "        if np.sum(action_probs) != 0:\n",
    "            action_probs /= np.sum(action_probs)\n",
    "        if np.isnan(action_probs[0]):\n",
    "            breakpoint()\n",
    "        return action_probs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self, model, optimizer, game:Yan, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(game, args, model)\n",
    "        \n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "        # player = 1\n",
    "        state = self.game.get_initial_state()\n",
    "        \n",
    "        while True:\n",
    "            # neutral_state = self.game.change_perspective(state, player)\n",
    "            action_probs = self.mcts.search(state)\n",
    "            \n",
    "            memory.append((state, action_probs))\n",
    "\n",
    "            if np.sum(action_probs) == 0:\n",
    "                breakpoint()\n",
    "                returnMemory = [(self.game.get_encoded_state(state), action_probs, 0)]\n",
    "                return returnMemory\n",
    "            \n",
    "            action = np.random.choice(self.game.get_number_of_actions(state), p=action_probs)\n",
    "            \n",
    "            state, reward, terminal = self.game.get_next_state(state, action)\n",
    "            \n",
    "            value, is_terminal = self.game.get_value_and_terminated(state, action)\n",
    "            \n",
    "            if is_terminal:\n",
    "                returnMemory = []\n",
    "                for hist_state, hist_action_probs in memory:\n",
    "                    hist_outcome = value\n",
    "                    returnMemory.append((\n",
    "                        self.game.get_encoded_state(hist_state),\n",
    "                        hist_action_probs,\n",
    "                        hist_outcome\n",
    "                    ))\n",
    "                return returnMemory\n",
    "            \n",
    "            # player = self.game.get_opponent(player)\n",
    "                \n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] \n",
    "            try:\n",
    "                state, policy_targets, value_targets = zip(*sample)\n",
    "                \n",
    "                state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "                \n",
    "                state = torch.tensor(state, dtype=torch.float32)\n",
    "                policy_targets = torch.tensor(policy_targets, dtype=torch.float32)\n",
    "                value_targets = torch.tensor(value_targets, dtype=torch.float32)\n",
    "                \n",
    "                out_policy, out_value = self.model(state)\n",
    "                \n",
    "                policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "                value_loss = F.mse_loss(out_value, value_targets)\n",
    "                loss = policy_loss + value_loss\n",
    "                \n",
    "                self.optimizer.zero_grad() # change to self.optimizer\n",
    "                loss.backward()\n",
    "                self.optimizer.step() # change to self.optimizer\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def learn(self):\n",
    "        for iteration in trange(self.args['num_iterations']):\n",
    "            memory = []\n",
    "            \n",
    "            self.model.eval()\n",
    "            for selfPlay_iteration in range(self.args['num_selfPlay_iterations']):\n",
    "                memory += self.selfPlay()\n",
    "                \n",
    "            self.model.train()\n",
    "            for epoch in range(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "            version = self.args['model_version']\n",
    "            if (iteration + 1) % 10 == 0:\n",
    "                torch.save(self.model.state_dict(), f\"models/model_{version}_{iteration}.pt\")\n",
    "                torch.save(self.optimizer.state_dict(), f\"models/optimizer_{version}_{iteration}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yan = Yan()\n",
    "# init_state = yan.get_initial_state()\n",
    "# print(init_state)\n",
    "# encoded_state = yan.get_encoded_state(init_state)\n",
    "# print(encoded_state)\n",
    "# dados = encoded_state[1]*66666\n",
    "# print(int(dados))\n",
    "# tabela = int(encoded_state[2]*8191)\n",
    "# print(tabela)\n",
    "\n",
    "# tabela = \"{0:b}\".format(tabela)\n",
    "# print(tabela)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_table = randint(0,8191)\n",
    "# print(initial_table)\n",
    "# tabela = \"{0:b}\".format(initial_table)\n",
    "# n_off_zeros = 13 - len(tabela)\n",
    "# for i in range(n_off_zeros):\n",
    "#     tabela = \"0\" + tabela\n",
    "\n",
    "# tabela_array = []\n",
    "# for i in range(13):\n",
    "#     tabela_array.append(int(tabela[i]))\n",
    "# print(tabela_array)\n",
    "\n",
    "# initial_reroll = randint(0,2)\n",
    "# print(initial_reroll)\n",
    "\n",
    "# initial_dice = []\n",
    "# for i in range(5):\n",
    "#     initial_dice.append(randint(1,6))\n",
    "# print(initial_dice)\n",
    "\n",
    "# initial_random_state = []\n",
    "# initial_random_state.append(initial_reroll)\n",
    "# initial_random_state += initial_dice\n",
    "# initial_random_state += tabela_array\n",
    "# print(initial_random_state)\n",
    "\n",
    "# encoded_state = []\n",
    "# encoded_state.append(initial_random_state[0]/2)\n",
    "# for i in range(1,6):\n",
    "#     encoded_state.append(initial_random_state[i]/6)\n",
    "# encoded_state += initial_random_state[6:]\n",
    "# print(encoded_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_params = {\n",
    "    \"go_for_n_factor\": 0.05,\n",
    "    \"go_for_q_factor\": 10,\n",
    "    \"go_for_f_factor\": 10,\n",
    "    \"go_for_s_factor\": 10,\n",
    "    \"go_for_s__factor\": 10,\n",
    "    \"go_for_y_factor\": 10,\n",
    "    \"go_for_x_factor\": 0,\n",
    "    \"go_for_x__factor\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"v0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9619667d91c4b798412cdb1ce7ef53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = \"modelsparams.json\"\n",
    "game = Yan()\n",
    "saved_models_param_dict = {}\n",
    "with open(filename) as json_file:\n",
    "        jsonObj = json.load(json_file)\n",
    "        unpickled = jsonpickle.decode(jsonObj, classes=Models_Params)\n",
    "saved_models_param_dict = unpickled\n",
    "\n",
    "model = ResNet(game, 4, 62)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "args = {\n",
    "    \n",
    "    'C': 2,\n",
    "    'num_searches': 220,\n",
    "    'num_iterations': 100,\n",
    "    'num_selfPlay_iterations': 200,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 128,\n",
    "    'model_version': model_version\n",
    "}\n",
    "saved_params = Models_Params(\n",
    "    args=args, \n",
    "    version=model_version, \n",
    "    policy_loss=\"cross_entropy\", \n",
    "    value_loss=\"mse_loss\",\n",
    "    optim=\"Adam\",\n",
    "    lr=0.0001,\n",
    "    game_params=game_params\n",
    "    )\n",
    "\n",
    "saved_models_param_dict[model_version] = saved_params\n",
    "\n",
    "with open(filename, \"w\") as outfile:\n",
    "    json.dump(jsonpickle.encode(saved_models_param_dict), outfile)\n",
    "\n",
    "\n",
    "alphaZero = AlphaZero(model, optimizer, game, args)\n",
    "alphaZero.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "game = Yan()\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 10000\n",
    "}\n",
    "# model = BobNet()\n",
    "model = ResNet(game, 4, 62)\n",
    "model.load_state_dict(torch.load(f\"models/model_{model_version}_99.pt\"))\n",
    "\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "\n",
    "\n",
    "def play_game():\n",
    "    state = game.get_initial_state()\n",
    "\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        game.get_valid_moves(state)\n",
    "        print(state)\n",
    "        print(f\"rerolls:        {state[0]}\")\n",
    "        print(f\"dice:           {state[1:6]}\")\n",
    "        print(f\"table:          {game.valid_moves_items}\")\n",
    "        mcts_probs = mcts.search(state)\n",
    "        action = np.argmax(mcts_probs)\n",
    "        print(f\"action:         {list(game.desordem.keys())[action]}\")\n",
    "        state, reward, is_terminal = game.get_next_state(state, action)\n",
    "        print(f\"reward:         {reward}\")\n",
    "        total_reward += reward\n",
    "        print(f\"total_reward:   {total_reward}\\n\")\n",
    "        if is_terminal:\n",
    "            print(game.desordem)\n",
    "            print(game.get_total_score(state))\n",
    "            game.reset()\n",
    "            break\n",
    "            \n",
    "\n",
    "play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yan = Yan()\n",
    "\n",
    "state = yan.get_initial_state()\n",
    "\n",
    "# state = yan.get_next_state(state, 2, 1)\n",
    "# state = yan.get_next_state(state, 7, -1)\n",
    "\n",
    "# print(state)\n",
    "\n",
    "encoded_state = yan.get_encoded_state(state)\n",
    "yan.get_valid_moves(state)\n",
    "print(state)\n",
    "print(f\"rerolls:        {state[0]}\")\n",
    "print(f\"dice:           {state[1:6]}\")\n",
    "print(f\"table:          {yan.valid_moves_items}\")\n",
    "# print(f\"action:         {list(game.desordem.keys())[action]}\")\n",
    "# state, reward, is_terminal = game.get_next_state(state, action)\n",
    "# print(f\"reward:         {reward}\")\n",
    "        \n",
    "\n",
    "tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
    "# model = BobNet().to(device)\n",
    "model = ResNet(yan, 4, 62)\n",
    "\n",
    "model.load_state_dict(torch.load(f\"models/model_{model_version}_99.pt\"))\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    policy, value = model(tensor_state)\n",
    "value = value.item()\n",
    "policy = torch.softmax(policy, axis=1)\n",
    "\n",
    "# print(value)\n",
    "# for action in policy[0]:\n",
    "#     print(action)\n",
    "\n",
    "plt.bar(range(13), policy.squeeze(0).numpy())  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound(\"done.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha-zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
