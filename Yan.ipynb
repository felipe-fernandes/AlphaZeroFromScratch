{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import diff\n",
    "from numpy import sum\n",
    "from random import randint\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Game_Moment(Enum):\n",
    "    SECOS_1 = 1\n",
    "    DADOS_1 = 2\n",
    "    SECOS_2 = 3\n",
    "    DADOS_2 = 4\n",
    "    TABELA = 5\n",
    "    FIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Yan:\n",
    "    def __init__(self):\n",
    "        # iniciar a coluna da desordem com -1 para indicar que as celulas estão vazias\n",
    "        self.desordem = {\"1\": -1, \"2\": -1, \"3\": -1, \"4\": -1, \"5\": -1, \"6\": -1, \"q\": -1, \"f\": -1, \"s+\": -1, \"s-\": -1, \"x+\": -1, \"x-\": -1, \"y\": -1}\n",
    "        self.yangame = \"YanGame\"\n",
    "        self.dices = [0,0,0,0,0]\n",
    "        self.current_state = Game_Moment.SECOS_1\n",
    "        self.new_dice = list()\n",
    "        self.marcado_em = \"\"\n",
    "        self.over_minimum = False\n",
    "        self.is_ended = False\n",
    "        self.game_play = []\n",
    "        self.next_state = self.get_game_state()\n",
    "        self.reward = 0\n",
    "        \n",
    "\n",
    "        # self.action_size = self.row_count * self.column_count\n",
    "    \n",
    "    def check_consecutive(self, l):\n",
    "        n = len(l) - 1\n",
    "        return sum(diff(sorted(l)) == 1) >= n\n",
    "\n",
    "\n",
    "    def roll_dice(self, n):\n",
    "        rolls = list()\n",
    "        for i in range(n):\n",
    "            rolls.append(randint(1, 6))\n",
    "        rolls.sort()\n",
    "        self.game_play.append(\"você rolou:                          \" + str(rolls))\n",
    "        return rolls\n",
    "\n",
    "\n",
    "    def get_game_state(self):\n",
    "        state = [self.current_state]\n",
    "        for die in self.dices:\n",
    "            state.append(die)\n",
    "        for item in self.desordem:\n",
    "            state.append(self.desordem[item])\n",
    "        return state\n",
    "        \n",
    "    def set_state(self, state):\n",
    "        self.current_state = state[0]\n",
    "        index = 1\n",
    "        for die in range(len(self.dices)):\n",
    "            self.dices[die] = state[index]\n",
    "            index += 1\n",
    "\n",
    "        index = 6\n",
    "        for item in self.desordem:\n",
    "            self.desordem[item] = state[index]\n",
    "            index += 1\n",
    "\n",
    "        return self.get_game_state()\n",
    "\n",
    "\n",
    "    # onde é possivel anotar o resultado dos dados\n",
    "    def get_empty_cells(self, state):\n",
    "        self.set_state(state)\n",
    "        avaiable_list = {}\n",
    "        for item in self.desordem:\n",
    "            if self.desordem[item] == -1:\n",
    "                avaiable_list[item] = self.desordem[item]\n",
    "        return avaiable_list\n",
    "    \n",
    "    def get_number_of_actions(self, state):\n",
    "        if state[0] == Game_Moment.TABELA:\n",
    "            # se estivermos na tabela, retornamos quantidade de celulas em branco\n",
    "            return len(self.get_empty_cells(state))\n",
    "        elif state[0] == Game_Moment.SECOS_1 or state[0] == Game_Moment.SECOS_2:\n",
    "            #se tivermos no SECO retornamos binário \"marcar/ não marcar\"\n",
    "            return 2\n",
    "        else:\n",
    "            # se estivermos nos dados retornamos 31 combinações de dados\n",
    "            return 31\n",
    "\n",
    "\n",
    "    def do_the_reroll(self, n_dices):\n",
    "        dices_to_reroll = '{0:05b}'.format(int(n_dices))\n",
    "        self.game_play.append(\"dados a serem rolados novamente:     \" + dices_to_reroll)\n",
    "        for index in range(len(str(dices_to_reroll))):\n",
    "            if dices_to_reroll[index] == \"1\":\n",
    "                self.dices[index] = self.roll_dice(1)[0]\n",
    "\n",
    "        self.dices.sort()\n",
    "        self.game_play.append(\"seus dados ficaram assim:            \" + str(self.dices))\n",
    "        dice_set = set(self.dices)\n",
    "        n_single = len(dice_set)\n",
    "        # return (6 - n_single) * 3\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.game_play = []\n",
    "        self.game_play.append(\"Jogo iniciado\")\n",
    "        self.desordem = {\"1\": -1, \"2\": -1, \"3\": -1, \"4\": -1, \"5\": -1, \"6\": -1, \"q\": -1, \"f\": -1, \"s+\": -1, \"s-\": -1,\n",
    "                         \"x+\": -1, \"x-\": -1,\n",
    "                         \"y\": -1}\n",
    "        self.current_state = Game_Moment.SECOS_1\n",
    "        self.dices = self.roll_dice(5)\n",
    "        self.dices.sort()\n",
    "        self.is_ended = False\n",
    "\n",
    "        return self.get_game_state()\n",
    "    \n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return self.reset()\n",
    "    \n",
    "\n",
    "    def get_valid_moves(self, state):\n",
    "        game_state = state[0]       \n",
    "        if game_state == Game_Moment.TABELA:\n",
    "            # se estivermos na tabela, retornamos quantidade de celulas em branco\n",
    "            return np.ones(len(self.get_empty_cells(state)))\n",
    "        elif game_state == Game_Moment.SECOS_1 or game_state == Game_Moment.SECOS_2:\n",
    "            #se tivermos no SECO retornamos binário \"marcar/ não marcar\"\n",
    "            return np.ones(2)\n",
    "        else:\n",
    "            # se estivermos nos dados retornamos 31 combinações de dados\n",
    "            return np.ones(31)\n",
    "        # return self.get_number_of_actions()\n",
    "        # return (state.reshape(-1) == 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    def set_cell_value(self, cell: str):\n",
    "        \n",
    "        self.game_play.append(\"você marcou                          \" + str(self.dices) + \" em \" + cell)\n",
    "        self.game_play.append(\"\\n\")\n",
    "        \n",
    "        # self.marcado_em = \n",
    "        # print(self.marcado_em)\n",
    "        points = 0\n",
    "\n",
    "        if cell == \"1\":\n",
    "            points = self.dices.count(1)\n",
    "            self.desordem[\"1\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"2\":\n",
    "            points = self.dices.count(2) *2\n",
    "            self.desordem[\"2\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"3\":\n",
    "            points = self.dices.count(3) * 3\n",
    "            self.desordem[\"3\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"4\":\n",
    "            points = self.dices.count(4) * 4\n",
    "            self.desordem[\"4\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"5\":\n",
    "            points = self.dices.count(5) * 5\n",
    "            self.desordem[\"5\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"6\":\n",
    "            points = self.dices.count(6) * 6\n",
    "            self.desordem[\"6\"] = points\n",
    "            return points\n",
    "        \n",
    "        elif cell == \"y\":\n",
    "            if self.dices[0] == self.dices[4]:\n",
    "                self.desordem[\"y\"] = sum(self.dices) + 50\n",
    "                return sum(self.dices) + 50\n",
    "            else:\n",
    "                self.desordem[\"y\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"q\":\n",
    "            if self.dices[0] == self.dices[3]:\n",
    "                self.desordem[\"q\"] = sum(self.dices[:4]) + 30\n",
    "                return sum(self.dices[:4]) + 30\n",
    "            elif self.dices[1] == self.dices[4]:\n",
    "                self.desordem[\"q\"] = sum(self.dices[1:]) + 30\n",
    "                return sum(self.dices[1:]) + 30\n",
    "            else:\n",
    "                self.desordem[\"q\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"f\":\n",
    "            if (self.dices[0] == self.dices[2] and self.dices[3] == self.dices[4]) or (\n",
    "                    self.dices[0] == self.dices[1] and self.dices[2] == self.dices[4]):\n",
    "                self.desordem[\"f\"] = sum(self.dices) + 20\n",
    "                return sum(self.dices) + 20\n",
    "\n",
    "            else:\n",
    "                self.desordem[\"f\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"s+\":\n",
    "            if self.check_consecutive(self.dices) and self.dices[0] == 2:\n",
    "                self.desordem[\"s+\"] = 60\n",
    "                return 60\n",
    "            else:\n",
    "                self.desordem[\"s+\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"s-\":\n",
    "            if self.check_consecutive( self.dices) and self.dices[0] == 1:\n",
    "                self.desordem[\"s-\"] = 50\n",
    "                return 50\n",
    "            else:\n",
    "                self.desordem[\"s-\"] = 0\n",
    "                return 0\n",
    "            \n",
    "        elif cell == \"x+\":\n",
    "            if (sum(self.dices) > self.desordem[\"x-\"]) or self.desordem[\"x-\"] == -1:\n",
    "                self.desordem[\"x+\"] = sum(self.dices)\n",
    "                return sum(self.dices)\n",
    "            else:\n",
    "                self.desordem[\"x+\"] = 0\n",
    "            return 0\n",
    "        \n",
    "        elif cell == \"x-\":\n",
    "            if (sum(self.dices) < self.desordem[\"x+\"]) or self.desordem[\"x+\"] == -1:\n",
    "                self.desordem[\"x-\"] = sum(self.dices)\n",
    "                return sum(self.dices)\n",
    "            else:\n",
    "                self.desordem[\"x-\"] = 0\n",
    "            return 0\n",
    "            \n",
    "\n",
    "    def get_next_state(self, state, action):\n",
    "        self.set_state(state)\n",
    "        action = int(action)\n",
    "        game_moment = state[0]       \n",
    "        if game_moment == Game_Moment.SECOS_1:\n",
    "            if action:\n",
    "                self.game_play.append(\"você escolheu marcar\")\n",
    "                self.current_state = Game_Moment.TABELA\n",
    "\n",
    "            else:\n",
    "                self.game_play.append(\"você escolheu jogar novamente\")\n",
    "                self.current_state = Game_Moment.DADOS_1\n",
    "\n",
    "            self.reward = 0\n",
    "            return (self.get_game_state())\n",
    "        \n",
    "        elif game_moment == Game_Moment.DADOS_1:\n",
    "            self.reward = self.do_the_reroll(n_dices=(int(action)+1))\n",
    "            self.current_state = Game_Moment.SECOS_2\n",
    "            return (self.get_game_state())\n",
    "            return (self.get_game_state(), self.reward, self.is_ended)\n",
    "        \n",
    "        elif game_moment == Game_Moment.SECOS_2:\n",
    "            if action:\n",
    "                self.game_play.append(\"você escolheu marcar\")\n",
    "                self.current_state = Game_Moment.TABELA\n",
    "            else:\n",
    "                self.game_play.append(\"você escolheu jogar novamente\")\n",
    "                self.current_state = Game_Moment.DADOS_2\n",
    "\n",
    "            self.reward = 0\n",
    "            return (self.get_game_state())\n",
    "            return (self.get_game_state(), self.reward, self.is_ended)\n",
    "\n",
    "        elif game_moment == Game_Moment.DADOS_2:\n",
    "            self.reward = self.do_the_reroll(n_dices=(action+1))\n",
    "            self.current_state = Game_Moment.TABELA\n",
    "            return (self.get_game_state())\n",
    "            return (self.get_game_state(), self.reward, self.is_ended)\n",
    "        \n",
    "        elif game_moment == Game_Moment.TABELA:\n",
    "            avaiable_cells = list(self.get_empty_cells(state).keys())\n",
    "            table_index = avaiable_cells[action]\n",
    "            self.game_play.append(\"suas opções são:                     \" + str(avaiable_cells))\n",
    "            self.reward = self.set_cell_value(table_index)\n",
    "            if -1 not in self.desordem.values():\n",
    "                self.game_play.append(\"fim do jogo\")\n",
    "                self.current_state = Game_Moment.FIM\n",
    "                return (self.get_game_state())\n",
    "                return (self.get_game_state(), self.reward, self.is_ended)\n",
    "            else:\n",
    "                self.is_ended = False\n",
    "                self.current_state = Game_Moment.SECOS_1\n",
    "                self.dices = self.roll_dice(5)\n",
    "                self.dices.sort()\n",
    "                return (self.get_game_state())\n",
    "                return (self.get_game_state(), self.reward, self.is_ended)\n",
    "            \n",
    "        else:\n",
    "            self.current_state = Game_Moment.FIM\n",
    "            self.is_ended = True\n",
    "            return (self.get_game_state())\n",
    "            return (self.get_game_state(), self.get_total_score(), self.is_ended)\n",
    "    \n",
    "\n",
    "    def check_ended(self, state):\n",
    "        self.set_state(state)\n",
    "        return -1 not in self.desordem.values()\n",
    "    \n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if action == None:\n",
    "            return (0, False)\n",
    "        self.set_state(state)\n",
    "        if self.check_ended(state):\n",
    "            return self.get_total_score(state), self.check_ended(state)\n",
    "        else:\n",
    "            return self.reward, self.check_ended(state)\n",
    "    \n",
    "\n",
    "    def get_total_score(self, state):\n",
    "        self.set_state(state)\n",
    "        self.score_values = list(self.desordem.values())\n",
    "        self.total = sum(self.score_values)\n",
    "        total_upper = sum(self.score_values[0:6])\n",
    "        if total_upper >= 60:\n",
    "            self.total += 30\n",
    "        # print()\n",
    "        self.game_play.append(\"sua tabela ficou assim:              \" + str(self.desordem))\n",
    "        self.game_play.append(\"TOTAL:                               \" + str(self.total))\n",
    "        print(\"total: \", self.total)\n",
    "        print(\"sua tabela ficou assim: \", self.desordem)\n",
    "        print()\n",
    "        \n",
    "\n",
    "        return self.total\n",
    "    \n",
    "    def get_encoded_state(self, state):\n",
    "        encoded = state.copy()\n",
    "        encoded[0] = state[0].value\n",
    "        encoded = np.stack(encoded).astype(np.float32)\n",
    "        return encoded\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 13\n",
    "NUM_FEATURES = 19\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BobNet(\n",
       "  (policyHead): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=13, bias=True)\n",
       "  )\n",
       "  (valueHead): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "class BobNet(nn.Module):\n",
    "    def __init__(self, input_features=NUM_FEATURES, output_features=NUM_CLASSES, hiden_units = 32, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hiden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hiden_units, out_features=hiden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hiden_units, out_features=output_features)\n",
    "        )\n",
    "        \n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hiden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hiden_units, out_features=hiden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hiden_units, out_features=1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "        \n",
    "policy_model = BobNet().to(device)\n",
    "policy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, num_resBlocks, num_hidden):\n",
    "        super().__init__()\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Linear(19, num_hidden),\n",
    "            nn.BatchNorm1d(num_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
    "        )\n",
    "        \n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Linear(num_hidden, 31),\n",
    "            nn.BatchNorm1d(31),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(31 * 19, 31)\n",
    "        )\n",
    "        \n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Linear(num_hidden, 3),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(19, 2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(num_hidden)\n",
    "        self.conv2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.bn2 = nn.BatchNorm1d(num_hidden)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17550776898860931 [0.07856873 0.0642374  0.09830496 0.06061105 0.05000038 0.07066485\n",
      " 0.06688178 0.11993363 0.0761923  0.06244614 0.08037648 0.08789266\n",
      " 0.08388968]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yan = Yan()\n",
    "\n",
    "state = yan.get_initial_state()\n",
    "# state = yan.get_next_state(state, 2, 1)\n",
    "# state = yan.get_next_state(state, 7, -1)\n",
    "\n",
    "# print(state)\n",
    "\n",
    "encoded_state = yan.get_encoded_state(state)\n",
    "\n",
    "# print(encoded_state)\n",
    "\n",
    "tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
    "model = BobNet().to(device)\n",
    "model.eval()\n",
    "\n",
    "policy, value = model(tensor_state)\n",
    "value = value.item()\n",
    "policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "print(value, policy)\n",
    "\n",
    "plt.bar(range(NUM_CLASSES), policy)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior\n",
    "        \n",
    "        self.children = []\n",
    "        \n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "        \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "        \n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "                \n",
    "        return best_child\n",
    "    \n",
    "    def get_ucb(self, child):\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
    "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
    "    \n",
    "    def expand(self, policy):\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob > 0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.get_next_state(child_state, action)\n",
    "\n",
    "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
    "                self.children.append(child)\n",
    "                \n",
    "        return child\n",
    "    \n",
    "            \n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "        \n",
    "        value = self.game.reward\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)  \n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game:Yan, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "    @torch.no_grad() \n",
    "    def search(self, state):\n",
    "        root = Node(self.game, self.args, state)\n",
    "        \n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "            \n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "                \n",
    "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "            \n",
    "            if not is_terminal:\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)\n",
    "                )   \n",
    "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "                # valid_moves = self.game.get_valid_moves(node.state)\n",
    "                # valid_sized_move = valid_moves + np.zeros(13)\n",
    "                # policy *= valid_sized_move\n",
    "                # policy /= np.sum(policy)\n",
    "                \n",
    "                value = value.item()\n",
    "                \n",
    "                node.expand(policy)\n",
    "                \n",
    "            node.backpropagate(value)    \n",
    "            \n",
    "            \n",
    "        action_probs = self.game.get_valid_moves(state)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Game_Moment.SECOS_1: 1>, 1, 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(state)\n\u001b[1;32m---> 17\u001b[0m     mcts_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmcts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(mcts_probs)\n\u001b[0;32m     20\u001b[0m     state \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_next_state(state, action)\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\anaconda3\\envs\\alpha-zero\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[73], line 88\u001b[0m, in \u001b[0;36mMCTS.search\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;66;03m# valid_moves = self.game.get_valid_moves(node.state)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;66;03m# valid_sized_move = valid_moves + np.zeros(13)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;66;03m# policy *= valid_sized_move\u001b[39;00m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;66;03m# policy /= np.sum(policy)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m         value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 88\u001b[0m         \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     node\u001b[38;5;241m.\u001b[39mbackpropagate(value)    \n\u001b[0;32m     93\u001b[0m action_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_valid_moves(state)\n",
      "Cell \u001b[1;32mIn[73], line 41\u001b[0m, in \u001b[0;36mNode.expand\u001b[1;34m(self, policy)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     40\u001b[0m     child_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 41\u001b[0m     child_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     child \u001b[38;5;241m=\u001b[39m Node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, child_state, \u001b[38;5;28mself\u001b[39m, action, prob)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend(child)\n",
      "Cell \u001b[1;32mIn[52], line 269\u001b[0m, in \u001b[0;36mYan.get_next_state\u001b[1;34m(self, state, action)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m game_moment \u001b[38;5;241m==\u001b[39m Game_Moment\u001b[38;5;241m.\u001b[39mTABELA:\n\u001b[0;32m    268\u001b[0m     avaiable_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_empty_cells(state)\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m--> 269\u001b[0m     table_index \u001b[38;5;241m=\u001b[39m \u001b[43mavaiable_cells\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_play\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuas opções são:                     \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(avaiable_cells))\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_cell_value(table_index)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "game = Yan()\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 100\n",
    "}\n",
    "model = BobNet()\n",
    "model.eval()\n",
    "mcts = MCTS(game, args, model)\n",
    "\n",
    "state = game.get_initial_state()\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "    \n",
    "    mcts_probs = mcts.search(state)\n",
    "    action = np.argmax(mcts_probs)\n",
    "        \n",
    "    state = game.get_next_state(state, action)\n",
    "    \n",
    "    value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "    \n",
    "    if is_terminal:\n",
    "        print(game.desordem)\n",
    "        print(game.get_total_score(state))\n",
    "        game.reset()\n",
    "        break\n",
    "        \n",
    "    # player = game.get_opponent(player)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha-zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
